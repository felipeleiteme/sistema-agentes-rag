model_list:
  # OpenAI GPT-4o
  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: os.environ/OPENAI_API_KEY
      temperature: 0.7
      max_tokens: 4000

  # Anthropic Claude 3 Haiku
  - model_name: claude-haiku
    litellm_params:
      model: anthropic/claude-3-haiku-20240307
      api_key: os.environ/ANTHROPIC_API_KEY
      temperature: 0.7
      max_tokens: 4000

  # Anthropic Claude 3.5 Sonnet (opcional)
  - model_name: claude-sonnet
    litellm_params:
      model: anthropic/claude-3-5-sonnet-20240620
      api_key: os.environ/ANTHROPIC_API_KEY
      temperature: 0.7
      max_tokens: 4000

# Configurações do Proxy
litellm_settings:
  drop_params: true
  set_verbose: false
  request_timeout: 600
  num_retries: 3

# Cache (opcional - desabilitado por padrão)
# cache:
#   type: redis
#   host: localhost
#   port: 6379

# Rate Limiting (opcional)
router_settings:
  routing_strategy: simple-shuffle
  model_group_alias:
    gpt-4: gpt-4o
    claude: claude-haiku

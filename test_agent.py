#!/usr/bin/env python3
"""Teste r√°pido do sistema de agentes com RAG"""
from langchain_ollama import ChatOllama
from tools import buscar_conhecimento_rh


def main():
    """Executa testes do sistema"""
    print("ü§ñ Teste do Sistema de Agentes com RAG\n")

    # Teste 1: Ferramenta RAG
    print("=" * 60)
    print("TESTE 1: Ferramenta RAG")
    print("=" * 60)

    pergunta = "Quantos dias de f√©rias CLT?"
    print(f"\nPergunta: {pergunta}")
    print("\nBuscando na base de conhecimento...")

    contexto = buscar_conhecimento_rh._run(pergunta)
    print(f"\n‚úÖ Contexto encontrado ({len(contexto)} caracteres):")
    print(contexto[:300] + "..." if len(contexto) > 300 else contexto)

    # Teste 2: LLM Ollama
    print("\n\n" + "=" * 60)
    print("TESTE 2: LLM Ollama")
    print("=" * 60)

    llm = ChatOllama(model="llama3.2:3b", temperature=0.7)

    print("\nPerguntando ao LLM...")
    prompt = f"""Voc√™ √© um especialista em RH.

CONTEXTO: {contexto}

PERGUNTA: {pergunta}

Responda de forma curta e direta em portugu√™s:"""

    print("\n‚è≥ Aguardando resposta do Llama...")
    resposta = llm.invoke(prompt)

    print(f"\n‚úÖ RESPOSTA DO LLM:")
    print(resposta.content)

    print("\n" + "=" * 60)
    print("‚úÖ TESTE CONCLU√çDO!")
    print("=" * 60)


if __name__ == "__main__":
    main()

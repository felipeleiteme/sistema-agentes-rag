# SAC Learning GEMS ğŸ’

**Sistema de Aprendizado Modular com 7 Agentes Especializados**

Sistema revolucionÃ¡rio de 7 GEMs (agentes especializados) que transformam a curva de aprendizado atravÃ©s de **aprendizado interativo** guiado por inteligÃªncia artificial local.

![Version](https://img.shields.io/badge/version-2.0.0-blue.svg)
![Python](https://img.shields.io/badge/python-3.11%2B-brightgreen.svg)
![Ollama](https://img.shields.io/badge/ollama-llama3.2:3b-orange.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

## ğŸŒŸ CaracterÃ­sticas Principais

- âœ… **100% Gratuito** - Sem APIs pagas, totalmente local
- âœ… **7 GEMs Especializados** - Agentes independentes e autossuficientes
- âœ… **Interface Web Moderna** - Chat interativo com streaming em tempo real
- âœ… **NavegaÃ§Ã£o Livre** - Explore qualquer GEM a qualquer momento
- âœ… **Progresso Visual** - Acompanhe sua jornada com indicadores claros
- âœ… **LLM Local** - Llama 3.2 (3B) via Ollama, privacidade total
- âœ… **Performance Otimizada** - Respostas rÃ¡pidas com streaming SSE

## ğŸ¯ O que sÃ£o os GEMs?

Os 7 GEMs sÃ£o agentes especializados que trabalham em sequÃªncia para criar um sistema personalizado de aprendizado:

| # | GEM | FunÃ§Ã£o | DuraÃ§Ã£o |
|---|-----|--------|---------|
| 1ï¸âƒ£ | ğŸ—ºï¸ **Mestre do Mapeamento** | Mapeia seus papÃ©is de vida (M.A.P.A.) | 45 min |
| 2ï¸âƒ£ | ğŸ” **Diagnosticador F.O.C.O.** | Clarifica problemas (Fatos, EmoÃ§Ãµes, Contexto) | 20-40 min |
| 3ï¸âƒ£ | âš–ï¸ **Validador EstratÃ©gico** | Valida investimento de energia | 30 min |
| 4ï¸âƒ£ | ğŸ”¬ **LaboratÃ³rio CientÃ­fico** | Encontra mÃ©todos cientÃ­ficos validados | 30-45 min |
| 5ï¸âƒ£ | ğŸ“ **Tutor SocrÃ¡tico** | Certifica domÃ­nio ativo | 60 min |
| 6ï¸âƒ£ | ğŸ—ï¸ **Arquiteto de ImplementaÃ§Ã£o** | Cria plano de implementaÃ§Ã£o | 40 min |
| 7ï¸âƒ£ | ğŸ’ **Construtor de Sistemas** | ConstrÃ³i assistente IA personalizado (KBF) | 30 min |

**Tempo total estimado:** 4-6 horas (distribuÃ­das em vÃ¡rios dias)

**Resultado final:** Um KBF (Knowledge-Based Fractal) - assistente IA que te conhece profundamente e adapta cada sugestÃ£o Ã  sua realidade Ãºnica.

## ğŸš€ InstalaÃ§Ã£o RÃ¡pida

### 1. PrÃ©-requisitos

```bash
# macOS
brew install ollama
brew services start ollama
ollama pull llama3.2:3b

# Linux
curl -fsSL https://ollama.com/install.sh | sh
ollama pull llama3.2:3b
```

### 2. Clone e Configure

```bash
git clone https://github.com/felipeleiteme/sistema-agentes-rag.git
cd sistema-agentes-rag
python3 -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Execute a Interface Web

```bash
uvicorn src.web.app:app --reload
```

Acesse **`http://localhost:8000`** no navegador.

## ğŸ“± Interface Web

A interface web oferece uma experiÃªncia moderna e intuitiva:

### âœ¨ Principais Features

- **Streaming em Tempo Real**: Veja as respostas aparecerem palavra por palavra
- **Sidebar de NavegaÃ§Ã£o**: Acesse qualquer GEM diretamente
- **Progresso Visual**: Barra de progresso e indicadores de conclusÃ£o
- **Design Responsivo**: Funciona perfeitamente em mobile e desktop
- **Tema Claro/Escuro**: Alterne entre temas com um clique
- **HistÃ³rico Persistente**: Suas conversas sÃ£o salvas localmente

### ğŸ¨ Componentes da Interface

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [â˜°]  SAC Learning GEMS              [ğŸŒ™]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚          â”‚                                  â”‚
â”‚  GEMs    â”‚     Chat Principal              â”‚
â”‚  â”€â”€â”€â”€â”€   â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”‚
â”‚          â”‚                                  â”‚
â”‚  âœ“ GEM 1 â”‚  [Streaming de Mensagens]       â”‚
â”‚  â†’ GEM 2 â”‚  [Respostas em Tempo Real]      â”‚
â”‚    GEM 3 â”‚  [HistÃ³rico Completo]           â”‚
â”‚    ...   â”‚                                  â”‚
â”‚          â”‚                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  42%     â”‚  [Digite sua mensagem...]  [â†‘]  â”‚
â”‚  GEM 3/7 â”‚                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ—ï¸ Arquitetura do Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Interface Web (FastAPI)           â”‚
â”‚  - Streaming SSE                            â”‚
â”‚  - NavegaÃ§Ã£o entre GEMs                     â”‚
â”‚  - Gerenciamento de estado                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   GEMService      â”‚
        â”‚   - Processa msgs â”‚
        â”‚   - Gerencia LLM  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  GEMOrchestrator   â”‚
        â”‚  - Controla fluxo  â”‚
        â”‚  - Persiste estado â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                           â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚  GEMs  â”‚              â”‚ Ollama LLM â”‚
â”‚  7     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ llama3.2:3bâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‚ Estrutura do Projeto

```
sistema-agentes-rag/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ gems.py              # DefiniÃ§Ãµes dos 7 GEMs
â”‚   â”‚   â”œâ”€â”€ orchestrator.py      # Orquestrador da jornada
â”‚   â”‚   â”œâ”€â”€ gems_service.py      # ServiÃ§o principal dos GEMs
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ web/
â”‚       â”œâ”€â”€ app.py               # FastAPI app com endpoints
â”‚       â”œâ”€â”€ static/
â”‚       â”‚   â”œâ”€â”€ app.js           # JavaScript (streaming, sidebar)
â”‚       â”‚   â””â”€â”€ styles.css       # Estilos modernos
â”‚       â””â”€â”€ templates/
â”‚           â”œâ”€â”€ base.html
â”‚           â””â”€â”€ index.html       # Interface principal
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ SAC_GEMS_README.md       # DocumentaÃ§Ã£o completa dos GEMs
â”‚   â”œâ”€â”€ COMECE_AQUI.md           # Guia de inÃ­cio rÃ¡pido
â”‚   â”œâ”€â”€ GUIA_RAPIDO_GEMS.md      # Resumo dos GEMs
â”‚   â”œâ”€â”€ MUDANCAS_v2.md           # Changelog da versÃ£o 2.0
â”‚   â”œâ”€â”€ OTIMIZACAO_PERFORMANCE.md # OtimizaÃ§Ãµes implementadas
â”‚   â””â”€â”€ CHANGELOG.md             # HistÃ³rico de mudanÃ§as
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sac_gems_knowledge.txt   # Base de conhecimento
â”œâ”€â”€ sac_gems.py                  # CLI interativo
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md                    # Este arquivo
```

## ğŸ® Como Usar

### 1. Interface Web (Recomendado)

```bash
uvicorn src.web.app:app --reload
```

Abra `http://localhost:8000` e:
1. Clique em **"ComeÃ§ar Jornada"**
2. Interaja com o GEM atual
3. Use a **sidebar** para navegar entre GEMs
4. Acompanhe seu **progresso visual**

### 2. CLI Interativo

```bash
python3 sac_gems.py
```

Comandos disponÃ­veis:
- `iniciar` - ComeÃ§a a jornada pelos GEMs
- `status` - Mostra seu progresso atual
- `listar` - Lista todos os GEMs disponÃ­veis
- `reiniciar` - RecomeÃ§a do zero
- `sair` - Encerra o programa

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### Ajustar ParÃ¢metros do LLM

Edite `src/agents/gems_service.py`:

```python
self.llm = ChatOllama(
    model="llama3.2:3b",
    temperature=0.4,      # Determinismo (0.0-1.0)
    num_predict=350,      # Tamanho da resposta
    num_ctx=1536,         # Tamanho do contexto
    num_thread=4          # Threads para CPU
)
```

### Mudar Modelo do Ollama

```bash
# Modelos disponÃ­veis
ollama list

# Usar modelo diferente
ollama pull llama3.1:8b

# Atualizar no cÃ³digo
model="llama3.1:8b"
```

### Personalizar Streaming

Ajuste o delay em `src/web/app.py`:

```python
# Velocidade do streaming (segundos)
delay = 0.03 if i < 10 else 0.02
```

## ğŸ“Š Endpoints da API

### GET /api/gems
Lista todos os GEMs disponÃ­veis e o GEM atual.

**Resposta:**
```json
{
  "gems": [...],
  "current_gem": "gem2_diagnosticador_foco"
}
```

### POST /api/chat
Envia uma mensagem (resposta completa).

**Request:**
```json
{
  "message": "OlÃ¡, quero comeÃ§ar"
}
```

### POST /api/chat/stream
Envia uma mensagem com streaming SSE.

**Stream Events:**
```javascript
data: {"type": "start"}
data: {"type": "chunk", "content": "palavra ", ...}
data: {"type": "done", "answer": "...", ...}
```

### POST /api/gems/{gem_id}/activate
Ativa um GEM especÃ­fico para navegaÃ§Ã£o livre.

### GET /api/status
Retorna o status atual da jornada.

### POST /api/reset
Reinicia a jornada do zero.

## ğŸ› Troubleshooting

### Ollama nÃ£o estÃ¡ rodando

```bash
# macOS
brew services start ollama

# Linux
sudo systemctl start ollama

# Verificar
ollama list
```

### Modelo nÃ£o encontrado

```bash
ollama pull llama3.2:3b
```

### Porta 8000 em uso

```bash
# Usar outra porta
uvicorn src.web.app:app --reload --port 8001
```

### Respostas lentas

- **Normal para modelos locais!** (~10-15s)
- Primeira execuÃ§Ã£o carrega o modelo (mais lento)
- Respostas subsequentes sÃ£o mais rÃ¡pidas
- Use modelo menor para mais velocidade: `llama3.2:1b`

### Warning sobre PyTorch

```
None of PyTorch, TensorFlow >= 2.0, or Flax have been found.
```

**Pode ignorar!** O sistema nÃ£o usa PyTorch.

## ğŸ“ˆ Performance

### OtimizaÃ§Ãµes Implementadas

- âœ… Streaming SSE para feedback imediato
- âœ… Contexto reduzido (1536 tokens) para processamento rÃ¡pido
- âœ… Respostas concisas (350 tokens max)
- âœ… Cache de serviÃ§os com `@lru_cache`
- âœ… CompressÃ£o GZIP para respostas HTTP
- âœ… Delay adaptativo no streaming (mais rÃ¡pido â†’ mais lento)

### Benchmarks

| OperaÃ§Ã£o | Tempo MÃ©dio |
|----------|-------------|
| Primeira resposta | 12-15s |
| Respostas subsequentes | 8-10s |
| Streaming (primeira palavra) | ~100ms |
| Carregamento da interface | <100ms |
| Troca entre GEMs | <50ms |

## ğŸ“ Tecnologias Utilizadas

| Tecnologia | VersÃ£o | Uso |
|------------|--------|-----|
| **Python** | 3.11+ | Linguagem base |
| **FastAPI** | Latest | Framework web |
| **LangChain** | Latest | OrquestraÃ§Ã£o de LLM |
| **Ollama** | Latest | Runtime LLM local |
| **Llama 3.2** | 3B | Modelo de linguagem |
| **JavaScript** | ES6+ | Frontend interativo |
| **CSS3** | - | EstilizaÃ§Ã£o moderna |

## ğŸ“š DocumentaÃ§Ã£o Adicional

- **[SAC GEMS README](docs/SAC_GEMS_README.md)** - DocumentaÃ§Ã£o completa dos GEMs
- **[Comece Aqui](docs/COMECE_AQUI.md)** - Guia de inÃ­cio rÃ¡pido
- **[Guia RÃ¡pido GEMS](docs/GUIA_RAPIDO_GEMS.md)** - Resumo dos 7 GEMs
- **[MudanÃ§as v2.0](docs/MUDANCAS_v2.md)** - O que hÃ¡ de novo
- **[OtimizaÃ§Ã£o de Performance](docs/OTIMIZACAO_PERFORMANCE.md)** - Detalhes tÃ©cnicos
- **[Changelog](docs/CHANGELOG.md)** - HistÃ³rico completo

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“ Roadmap

- [ ] Suporte para mÃºltiplos usuÃ¡rios
- [ ] IntegraÃ§Ã£o com banco de dados
- [ ] ExportaÃ§Ã£o de jornadas em PDF
- [ ] Modo offline completo
- [ ] App mobile (React Native)
- [ ] Suporte para mais modelos LLM
- [ ] Sistema de notificaÃ§Ãµes

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ™ Agradecimentos

- Meta AI pelo Llama 3.2
- Ollama pela infraestrutura local
- LangChain pelo framework
- Comunidade open source

## ğŸ“§ Contato

Felipe Leite - [@felipeleiteme](https://github.com/felipeleiteme)

Link do Projeto: [https://github.com/felipeleiteme/sistema-agentes-rag](https://github.com/felipeleiteme/sistema-agentes-rag)

---

â­ Se este projeto te ajudou, considere dar uma estrela!

**Desenvolvido com â¤ï¸ usando IA local**

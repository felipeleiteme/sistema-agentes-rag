# üìã Guia Completo de Testes e Valida√ß√£o

Este guia fornece instru√ß√µes detalhadas para testar e validar todos os componentes do sistema.

## üìë √çndice

- [Pr√©-requisitos](#pr√©-requisitos)
- [Prepara√ß√£o do Ambiente](#prepara√ß√£o-do-ambiente)
- [Testes do Sistema Simples (CLI)](#testes-do-sistema-simples-cli)
- [Testes da Interface Web](#testes-da-interface-web)
- [Testes Automatizados](#testes-automatizados)
- [Testes do Sistema Avan√ßado (CrewAI)](#testes-do-sistema-avan√ßado-crewai)
- [Checklist de Valida√ß√£o](#checklist-de-valida√ß√£o)
- [Troubleshooting](#troubleshooting)

---

## Pr√©-requisitos

Antes de come√ßar os testes, certifique-se de ter:

- ‚úÖ **Python 3.11+** instalado
- ‚úÖ **Ollama** instalado e rodando
- ‚úÖ **Modelo Llama 3.2 (3B)** baixado
- ‚úÖ **Vari√°veis de ambiente** configuradas (arquivo `.env`)

---

## Prepara√ß√£o do Ambiente

### PASSO 1: Ativar Ambiente Virtual

```bash
cd /caminho/para/meu_sistema_agentes
source .venv/bin/activate
```

### PASSO 2: Instalar Depend√™ncias

```bash
pip install -r requirements.txt
```

### PASSO 3: Verificar Ollama

```bash
# Verificar se Ollama est√° rodando
ollama list

# Deve mostrar o modelo llama3.2:3b
# Se n√£o tiver, instalar:
ollama pull llama3.2:3b

# Testar o modelo
ollama run llama3.2:3b "Ol√°, como voc√™ est√°?"
```

**Sa√≠da esperada:**
```
NAME              ID              SIZE      MODIFIED
llama3.2:3b       abc123def...    2.0 GB    X days ago
```

### PASSO 4: Criar √çndice FAISS

```bash
python ingest.py
```

**Sa√≠da esperada:**
```
Iniciando ingest√£o da base de conhecimento (usando embeddings TF-IDF)...
Carregando base de conhecimento a partir de: /caminho/docs/politica_rh.txt
Documento dividido em 8 peda√ßos.
Criando banco de dados vetorial FAISS...
‚úÖ Base de conhecimento criada e salva como 'faiss_index'.
```

---

## Testes do Sistema Simples (CLI)

### Teste 1: Demonstra√ß√£o Autom√°tica

```bash
python simple_agent.py --demo
```

**O que esperar:**
- Sistema executa 3 perguntas pr√©-definidas
- Mostra classifica√ß√£o autom√°tica (RH vs Geral)
- Exibe respostas dos agentes

**Sa√≠da esperada:**
```
üéØ DEMONSTRA√á√ÉO DO SISTEMA

============================================================
TESTE: Pergunta sobre RH
============================================================

üìã Pergunta recebida: Quantos dias de f√©rias tem um funcion√°rio CLT?
------------------------------------------------------------
‚úÖ Detectado: Pergunta sobre RH ‚Üí Usando Agente RH com RAG
--- Ferramenta RAG Recebeu a Pergunta: Quantos dias de f√©rias...
--- Contexto Encontrado: Funcion√°rios CLT t√™m direito a 30 dias...

üì§ RESPOSTA:
Funcion√°rios CLT t√™m direito a 30 dias corridos de f√©rias ap√≥s 12 meses de trabalho.

============================================================
TESTE: Pergunta Geral
============================================================

üìã Pergunta recebida: Qual a capital do Brasil?
------------------------------------------------------------
‚úÖ Detectado: Pergunta geral ‚Üí Usando Agente Assistente

üì§ RESPOSTA:
A capital do Brasil √© Bras√≠lia.

============================================================
TESTE: Outra Pergunta sobre RH
============================================================

üìã Pergunta recebida: Qual o valor do b√¥nus anual para funcion√°rios PJ?
------------------------------------------------------------
‚úÖ Detectado: Pergunta sobre RH ‚Üí Usando Agente RH com RAG

üì§ RESPOSTA:
Funcion√°rios PJ recebem b√¥nus anual de R$5.000,00 mediante entrega de projetos.

============================================================
‚úÖ DEMONSTRA√á√ÉO CONCLU√çDA!
============================================================
```

### Teste 2: Pergunta √önica

```bash
python simple_agent.py -q "Quantos dias de f√©rias tem um funcion√°rio CLT?"
```

**Valida√ß√µes:**
- ‚úÖ Sistema identifica como pergunta de RH
- ‚úÖ Usa ferramenta RAG
- ‚úÖ Retorna resposta baseada na base de conhecimento

### Teste 3: Modo Interativo

```bash
python simple_agent.py
```

**Perguntas para testar:**

1. **Pergunta sobre RH:**
   ```
   Quantos dias de f√©rias tenho direito?
   ```

2. **Pergunta Geral:**
   ```
   Qual a capital do Brasil?
   ```

3. **Pergunta sobre Benef√≠cios:**
   ```
   Como funciona o regime PJ?
   ```

4. **Pergunta sobre B√¥nus:**
   ```
   Qual o valor do b√¥nus anual para CLT?
   ```

**Para sair:**
```
sair
```

---

## Testes da Interface Web

### PASSO 1: Iniciar Servidor Web

```bash
# Terminal 1
cd /caminho/para/meu_sistema_agentes
source .venv/bin/activate
uvicorn src.web.app:app --reload --host 0.0.0.0 --port 8000
```

**Sa√≠da esperada:**
```
INFO:     Will watch for changes in these directories: ['/caminho/meu_sistema_agentes']
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     Started reloader process [12345] using StatReload
INFO:     Started server process [12346]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
```

### PASSO 2: Testar Interface no Navegador

1. **Abra o navegador em:** `http://localhost:8000`

2. **Voc√™ ver√°:**
   - Interface web moderna com tema escuro
   - Campo de texto para perguntas
   - Bot√£o "Enviar"
   - √Årea de hist√≥rico de conversas

3. **Fa√ßa estas perguntas:**

   **Pergunta 1 (RH):**
   ```
   Quantos dias de f√©rias tem um funcion√°rio CLT?
   ```

   **Resultado esperado:**
   - Mensagem aparece na √°rea de chat
   - Mostra badge "üè¢ Agente RH"
   - Exibe "‚úÖ Contexto usado"
   - Mostra preview do contexto da base

   **Pergunta 2 (Geral):**
   ```
   Qual a capital do Brasil?
   ```

   **Resultado esperado:**
   - Mensagem aparece na √°rea de chat
   - Mostra badge "üí¨ Assistente"
   - Exibe "‚ö™ Sem contexto"

   **Pergunta 3 (RH):**
   ```
   Qual o valor do b√¥nus anual para funcion√°rios PJ?
   ```

### PASSO 3: Testar API REST Diretamente

```bash
# Terminal 2 (novo terminal)
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"question":"Quantos dias de f√©rias tem um funcion√°rio CLT?"}'
```

**Resposta esperada (JSON):**
```json
{
  "question": "Quantos dias de f√©rias tem um funcion√°rio CLT?",
  "answer": "Funcion√°rios CLT t√™m direito a 30 dias corridos de f√©rias ap√≥s 12 meses de trabalho.",
  "agent": "rh",
  "used_context": true,
  "context_preview": "Funcion√°rios CLT t√™m direito a 30 dias corridos de f√©rias ap√≥s 12 meses de trabalho...",
  "error": null
}
```

### PASSO 4: Testar Health Check

```bash
curl http://localhost:8000/
```

Deve retornar o HTML da p√°gina principal.

---

## Testes Automatizados

### Executar Todos os Testes

```bash
pytest tests/ -v
```

**Sa√≠da esperada:**
```
tests/test_agent_service.py::test_classify_hr_question PASSED
tests/test_agent_service.py::test_classify_general_question PASSED
tests/test_agent_service.py::test_answer_hr_question PASSED
tests/test_agent_service.py::test_answer_general_question PASSED
tests/test_web_app.py::test_read_home PASSED
tests/test_web_app.py::test_chat_endpoint PASSED

========================= 6 passed in 2.34s =========================
```

### Executar Teste Espec√≠fico

```bash
# Testar apenas servi√ßo de agentes
pytest tests/test_agent_service.py -v

# Testar apenas API web
pytest tests/test_web_app.py -v
```

### Executar com Cobertura

```bash
pytest tests/ --cov=src --cov-report=term-missing
```

---

## Testes do Sistema Avan√ßado (CrewAI)

‚ö†Ô∏è **Estes testes requerem LiteLLM Proxy e APIs pagas (OpenAI/Anthropic)**

### PASSO 1: Configurar Vari√°veis de Ambiente

Verifique se o arquivo `.env` cont√©m:

```bash
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
LITELLM_PROXY_URL=http://localhost:4000
```

### PASSO 2: Iniciar LiteLLM Proxy

```bash
# Terminal separado
cd /caminho/para/meu_sistema_agentes
litellm --config config/litellm_config.yaml --port 4000
```

**Sa√≠da esperada:**
```
INFO:     Started server process [12345]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:4000
```

### PASSO 3: Testar Health do Proxy

```bash
curl http://localhost:4000/health
```

**Resposta esperada:**
```json
{"status": "healthy"}
```

### PASSO 4: Testar Agentes CrewAI

Crie um arquivo de teste `test_crew_manual.py`:

```python
from src.agents.crew_agents import ResearchCrew

def test_research_crew():
    crew = ResearchCrew()
    result = crew.create_crew("pol√≠ticas de f√©rias da empresa").kickoff()
    print("\n" + "="*60)
    print("RESULTADO DA CREW:")
    print("="*60)
    print(result)
    print("="*60)

if __name__ == "__main__":
    test_research_crew()
```

Execute:

```bash
python test_crew_manual.py
```

---

## Checklist de Valida√ß√£o

### ‚úÖ Sistema Simple Agent (Ollama)

- [ ] **Ingest√£o**: `python ingest.py` cria `faiss_index/` sem erros
- [ ] **Classifica√ß√£o**: Sistema distingue perguntas RH de gerais
- [ ] **Agente RH**: Responde com contexto da base de conhecimento
- [ ] **Agente Geral**: Responde sem usar RAG
- [ ] **Modo Demo**: `--demo` executa 3 testes automaticamente
- [ ] **Modo Interativo**: Aceita perguntas livres e sai com "sair"
- [ ] **Modo Pergunta √önica**: `-q "pergunta"` funciona

### ‚úÖ Interface Web

- [ ] **Servidor**: Inicia sem erros na porta 8000
- [ ] **P√°gina**: `http://localhost:8000` carrega interface
- [ ] **Chat**: Perguntas retornam respostas na interface
- [ ] **API**: `POST /api/chat` retorna JSON v√°lido
- [ ] **Hist√≥rico**: Mensagens aparecem na √°rea de chat
- [ ] **Badges**: Mostra corretamente agente usado e contexto
- [ ] **Responsivo**: Interface funciona em diferentes tamanhos de tela

### ‚úÖ Testes Automatizados

- [ ] **pytest**: Todos os testes passam (6/6)
- [ ] **Servi√ßo**: Testes de classifica√ß√£o funcionam
- [ ] **API**: Endpoints retornam status 200
- [ ] **Erro Handling**: Erros s√£o tratados corretamente

### ‚úÖ Sistema CrewAI (Opcional)

- [ ] **Proxy**: LiteLLM inicia e responde em `/health`
- [ ] **Configura√ß√£o**: APIs OpenAI e Anthropic est√£o v√°lidas
- [ ] **RAG Tool**: Ferramenta busca documentos corretamente
- [ ] **Agentes**: Crew executa tarefas sequencialmente
- [ ] **Modelos**: GPT-4o, Claude Haiku e Sonnet acess√≠veis

---

## Troubleshooting

### ‚ùå Erro: "Model not found" / "llama3.2:3b not available"

**Solu√ß√£o:**
```bash
ollama pull llama3.2:3b
ollama list  # Verificar se aparece
```

### ‚ùå Erro: "FAISS index not found"

**Solu√ß√£o:**
```bash
python ingest.py
ls faiss_index/  # Deve mostrar index.faiss e index.pkl
```

### ‚ùå Erro: "Connection refused" ao acessar API

**Causa:** Porta 8000 j√° est√° em uso

**Solu√ß√£o:**
```bash
# Ver processo usando a porta
lsof -i :8000

# Matar processo
kill -9 <PID>

# Ou usar outra porta
uvicorn src.web.app:app --reload --port 8001
```

### ‚ùå Erro: "Ollama connection error"

**Solu√ß√£o:**
```bash
# Verificar se Ollama est√° rodando
brew services list | grep ollama

# Iniciar se necess√°rio
brew services start ollama

# Testar conex√£o
curl http://localhost:11434/api/tags
```

### ‚ùå Erro: "OpenAI API key invalid" (CrewAI)

**Solu√ß√£o:**
```bash
# Verificar se chave est√° no .env
cat .env | grep OPENAI_API_KEY

# Testar chave
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

### ‚ùå Respostas muito lentas (>30s)

**Poss√≠veis causas:**
1. **Primeira execu√ß√£o** - Ollama carrega modelo (normal)
2. **Hardware limitado** - Modelo 3B precisa de RAM suficiente
3. **Ollama sobrecarregado** - Reinicie o servi√ßo

**Solu√ß√£o:**
```bash
brew services restart ollama
```

### ‚ùå Erro: "No module named 'sklearn'"

**Solu√ß√£o:**
```bash
pip install scikit-learn>=1.3.0
```

### ‚ùå Erro: "No module named 'langchain_ollama'"

**Solu√ß√£o:**
```bash
pip install langchain-ollama==0.1.3
```

### ‚ùå Interface web n√£o carrega CSS/JS

**Causa:** Arquivos est√°ticos n√£o encontrados

**Solu√ß√£o:**
```bash
# Verificar se arquivos existem
ls src/web/static/
ls src/web/templates/

# Reiniciar servidor
uvicorn src.web.app:app --reload
```

---

## Logs e Diagn√≥stico

### Ver logs do Ollama

```bash
# macOS
tail -f ~/.ollama/logs/server.log

# Linux
journalctl -u ollama -f
```

### Ver processos ativos

```bash
ps aux | grep -E "ollama|uvicorn|litellm"
```

### Testar conectividade com Ollama

```bash
# Listar modelos dispon√≠veis
curl http://localhost:11434/api/tags

# Testar gera√ß√£o
curl http://localhost:11434/api/generate -d '{
  "model": "llama3.2:3b",
  "prompt": "Ol√°!",
  "stream": false
}'
```

### Verificar uso de mem√≥ria

```bash
# Ver uso de RAM
top -o MEM | head -20

# Ver uso do Ollama especificamente
ps aux | grep ollama | awk '{print $4}'  # % mem√≥ria
```

---

## Exemplo de Sess√£o Completa

```bash
# Terminal 1: Preparar ambiente
cd /caminho/para/meu_sistema_agentes
source .venv/bin/activate
python ingest.py

# Terminal 1: Testar CLI
python simple_agent.py --demo

# Terminal 2: Iniciar servidor web
cd /caminho/para/meu_sistema_agentes
source .venv/bin/activate
uvicorn src.web.app:app --reload --port 8000

# Terminal 3: Testar API
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"question":"Quantos dias de f√©rias tem funcion√°rio CLT?"}'

# Terminal 4: Rodar testes automatizados
pytest tests/ -v

# Navegador: Abrir interface
open http://localhost:8000
```

---

## üéØ Crit√©rios de Sucesso Final

O sistema est√° **100% funcional** se:

1. ‚úÖ `python ingest.py` cria √≠ndice sem erros
2. ‚úÖ `python simple_agent.py --demo` executa 3 testes com sucesso
3. ‚úÖ Interface web acess√≠vel em `http://localhost:8000`
4. ‚úÖ API retorna JSON v√°lido em `/api/chat`
5. ‚úÖ `pytest tests/ -v` - todos os 6 testes passam
6. ‚úÖ Perguntas sobre RH usam RAG
7. ‚úÖ Perguntas gerais n√£o usam RAG
8. ‚úÖ Respostas aparecem em menos de 20 segundos

---

## üìû Suporte

Se encontrar problemas n√£o listados aqui:

1. Verifique os logs do Ollama
2. Confirme que todas as depend√™ncias est√£o instaladas
3. Teste cada componente isoladamente
4. Revise o arquivo `.env`

**Boa sorte com os testes! üöÄ**
